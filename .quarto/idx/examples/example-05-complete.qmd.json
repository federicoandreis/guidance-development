{"title":"Example 5: Regional A&E Performance","markdown":{"yaml":{"title":"Example 5: Regional A&E Performance","subtitle":"Two-Sample t-test","number-sections":false},"headingText":"| include: false","containsRefs":false,"markdown":"\n\n```{r}\n# Setup Python environment\nlibrary(reticulate)\n```\n\n## Scenario Overview\n\n**Method**: Two-sample (independent) t-test (@sec-t-tests)  \n**Complexity**: Medium  \n**Time to complete**: 2-3 hours  \n**Status**: âœ… Complete\n\n::: {.callout-note icon=false}\n## ðŸ“– Method Reference\nFor detailed explanation of t-test methodology, two-sample design considerations, and step-by-step guidance, see @sec-t-tests.\n:::\n\n---\n\n## ðŸ“‹ Scenario\n\nYou are comparing A&E 4-hour wait performance between two Integrated Care Systems (ICS): North Region ICS and South Region ICS. Each ICS contains 100 hospital trusts. Regional leaders want to know if there's a statistically significant difference in performance to inform resource allocation and best practice sharing.\n\n**Analytical Question**: Is there a significant difference in A&E 4-hour wait performance between North Region ICS and South Region ICS?\n\n**Context**: The NHS target is for 95% of A&E patients to be seen within 4 hours. Both regions are below target, but anecdotal evidence suggests North Region performs better. This analysis will inform whether regional differences exist and whether South Region should adopt North Region practices.\n\n---\n\n## ðŸŽ¯ Learning Objectives\n\nBy working through this example, you will learn to:\n\n1. **Understand independent samples design** vs paired design\n2. **Check assumptions** for two-sample t-test (normality, equal variances)\n3. **Apply Welch's t-test** when variances are unequal\n4. **Interpret confidence intervals** for difference between means\n5. **Consider confounding variables** (trust size, deprivation)\n6. **Assess practical vs statistical significance**\n7. **Conduct subgroup analysis** to explore heterogeneity\n8. **Communicate findings** with appropriate caveats\n\n---\n\n## ðŸ“Š Dataset Description\n\n### Synthetic Data: `data/ae_performance_data.csv`\n\n**200 hospital trusts** (100 per ICS) with the following variables:\n\n| Variable | Description | Type | Notes |\n|----------|-------------|------|-------|\n| `trust_code` | Trust identifier | String | Format: RXX001-RXX200 |\n| `trust_name` | Trust name | String | Synthetic names |\n| `ics` | Integrated Care System | String | North / South |\n| `ae_performance` | % seen within 4 hours | Float | 60-85% |\n| `monthly_attendances` | Monthly A&E attendances | Integer | 5000-25000 |\n| `deprivation_score` | Area deprivation (IMD) | Float | 10-40 |\n| `beds` | Hospital beds | Integer | 200-1000 |\n\n### Data Characteristics\n\n**Realistic patterns**:\n- North Region: slightly better performance (mean ~75%)\n- South Region: slightly worse performance (mean ~72%)\n- Variation within each region\n- Deprivation correlation (more deprived = worse performance)\n- Trust size variation\n\n**Data generation**: Synthetic data generated using R (`set.seed(42)`). North Region has 3% better performance on average. Both R and Python load the same CSV file, ensuring identical results.\n\n---\n\n## Step 1: Data Preparation\n\n**Purpose**: Load realistic A&E performance data for two regions.\n\n---\n\n::: {.panel-tabset}\n\n### R\n\n```{r ex5-generate-r}\n#| message: false\n#| warning: false\n\nlibrary(ggplot2)\n\n# Import A&E performance data\nae_data <- read.csv(\"data/ae_performance_data.csv\", stringsAsFactors = FALSE)\n\n# Display first few rows from each region\nhead(ae_data[ae_data$ics == \"North\", ])\nhead(ae_data[ae_data$ics == \"South\", ])\n\n# Summary by region\naggregate(ae_performance ~ ics, data = ae_data, \n          FUN = function(x) c(n = length(x), \n                              mean = round(mean(x), 2),\n                              sd = round(sd(x), 2),\n                              min = round(min(x), 2),\n                              max = round(max(x), 2)))\n```\n\n### Python\n\n```{python ex5-generate-py}\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\n\n# Import A&E performance data\nae_data = pd.read_csv(\"data/ae_performance_data.csv\")\n\n# Display first few rows from each region\nprint(\"North Region:\")\nprint(ae_data[ae_data['ics'] == \"North\"].head())\nprint(\"\\nSouth Region:\")\nprint(ae_data[ae_data['ics'] == \"South\"].head())\n\n# Summary by region\nprint(\"\\nSummary by region:\")\nprint(ae_data.groupby('ics')['ae_performance'].describe())\n```\n\n:::\n\n**Initial observations**:\n- North Region: mean ~75%\n- South Region: mean ~72%\n- Similar variation in both regions\n- Both well below 95% target\n\n---\n\n## Step 2: Visualize Distributions\n\n**Purpose**: Compare distributions between regions visually.\n\n---\n\n::: {.panel-tabset}\n\n### R\n\n```{r ex5-viz-r}\n#| fig-width: 12\n#| fig-height: 6\n\n# Side-by-side histograms\nnorth_mean <- mean(ae_data$ae_performance[ae_data$ics == \"North\"])\nsouth_mean <- mean(ae_data$ae_performance[ae_data$ics == \"South\"])\n\nggplot(ae_data, aes(x = ae_performance, fill = ics)) +\n  geom_histogram(bins = 20, alpha = 0.6, position = \"identity\") +\n  geom_vline(xintercept = north_mean, color = \"steelblue\", linetype = \"dashed\", size = 1) +\n  geom_vline(xintercept = south_mean, color = \"coral\", linetype = \"dashed\", size = 1) +\n  scale_fill_manual(values = c(\"North\" = \"steelblue\", \"South\" = \"coral\")) +\n  labs(\n    title = \"A&E 4-Hour Performance by Region\",\n    subtitle = \"Dashed lines show regional means\",\n    x = \"% Seen Within 4 Hours\",\n    y = \"Number of Trusts\",\n    fill = \"Region\"\n  ) +\n  theme_minimal()\n\n# Boxplots\nggplot(ae_data, aes(x = ics, y = ae_performance, fill = ics)) +\n  geom_boxplot(alpha = 0.6) +\n  geom_jitter(width = 0.2, alpha = 0.3) +\n  scale_fill_manual(values = c(\"North\" = \"steelblue\", \"South\" = \"coral\")) +\n  labs(\n    title = \"A&E Performance: North vs South Region\",\n    x = \"Region\",\n    y = \"% Seen Within 4 Hours\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n```\n\n### Python\n\n```{python ex5-viz-py}\n# Side-by-side histograms\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n\n# Histograms\nnorth_data = ae_data[ae_data['ics'] == 'North']['ae_performance']\nsouth_data = ae_data[ae_data['ics'] == 'South']['ae_performance']\n\nax1.hist(north_data, bins=20, alpha=0.6, label='North', color='steelblue')\nax1.hist(south_data, bins=20, alpha=0.6, label='South', color='coral')\nax1.axvline(north_data.mean(), color='steelblue', linestyle='--', linewidth=2)\nax1.axvline(south_data.mean(), color='coral', linestyle='--', linewidth=2)\nax1.set_xlabel('% Seen Within 4 Hours')\nax1.set_ylabel('Number of Trusts')\nax1.set_title('A&E 4-Hour Performance by Region\\nDashed lines show regional means')\nax1.legend()\nax1.grid(True, alpha=0.3)\n\n# Boxplots\nbp = ax2.boxplot([north_data, south_data], labels=['North', 'South'], patch_artist=True)\nbp['boxes'][0].set_facecolor('steelblue')\nbp['boxes'][1].set_facecolor('coral')\nax2.set_ylabel('% Seen Within 4 Hours')\nax2.set_title('A&E Performance: North vs South Region')\nax2.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n```\n\n:::\n\n**Observations**:\n- North Region appears to have higher mean\n- Distributions look approximately normal\n- Similar spread (variance) in both regions\n- Substantial overlap between regions\n\n---\n\n## Step 3: Check Assumptions\n\n**Purpose**: Verify two-sample t-test assumptions.\n\n---\n\n### Assumption 1: Normality\n\n::: {.panel-tabset}\n\n### R\n\n```{r ex5-normality-r}\n# Shapiro-Wilk test for each region\nnorth_shapiro <- shapiro.test(ae_data$ae_performance[ae_data$ics == \"North\"])\nsouth_shapiro <- shapiro.test(ae_data$ae_performance[ae_data$ics == \"South\"])\n\ncat(\"North Region Shapiro-Wilk p-value:\", round(north_shapiro$p.value, 3), \"\\n\")\ncat(\"South Region Shapiro-Wilk p-value:\", round(south_shapiro$p.value, 3), \"\\n\")\ncat(\"\\nInterpretation: Both p > 0.05, no evidence against normality\\n\")\n\n# Q-Q plots\npar(mfrow = c(1, 2))\nqqnorm(ae_data$ae_performance[ae_data$ics == \"North\"], main = \"Q-Q Plot: North Region\")\nqqline(ae_data$ae_performance[ae_data$ics == \"North\"], col = \"red\")\nqqnorm(ae_data$ae_performance[ae_data$ics == \"South\"], main = \"Q-Q Plot: South Region\")\nqqline(ae_data$ae_performance[ae_data$ics == \"South\"], col = \"red\")\npar(mfrow = c(1, 1))\n```\n\n### Python\n\n```{python ex5-normality-py}\n# Shapiro-Wilk test for each region\nnorth_stat, north_p = stats.shapiro(north_data)\nsouth_stat, south_p = stats.shapiro(south_data)\n\nprint(f\"North Region Shapiro-Wilk p-value: {north_p:.3f}\")\nprint(f\"South Region Shapiro-Wilk p-value: {south_p:.3f}\")\nprint(\"\\nInterpretation: Both p > 0.05, no evidence against normality\")\n\n# Q-Q plots\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n\nstats.probplot(north_data, dist=\"norm\", plot=ax1)\nax1.set_title(\"Q-Q Plot: North Region\")\nax1.grid(True, alpha=0.3)\n\nstats.probplot(south_data, dist=\"norm\", plot=ax2)\nax2.set_title(\"Q-Q Plot: South Region\")\nax2.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n```\n\n:::\n\n### Assumption 2: Equal Variances\n\n::: {.panel-tabset}\n\n### R\n\n```{r ex5-variance-r}\n# F-test for equality of variances\nnorth_perf <- ae_data$ae_performance[ae_data$ics == \"North\"]\nsouth_perf <- ae_data$ae_performance[ae_data$ics == \"South\"]\nvar_test <- var.test(north_perf, south_perf)\nprint(var_test)\n\ncat(\"\\nInterpretation:\", \n    ifelse(var_test$p.value > 0.05,\n           \"No evidence of unequal variances (p > 0.05) - use standard t-test\",\n           \"Evidence of unequal variances (p < 0.05) - use Welch's t-test\"), \"\\n\")\n\n# Compare standard deviations\nnorth_sd <- sd(ae_data$ae_performance[ae_data$ics == \"North\"])\nsouth_sd <- sd(ae_data$ae_performance[ae_data$ics == \"South\"])\ncat(\"\\nNorth SD:\", round(north_sd, 2), \"\\n\")\ncat(\"South SD:\", round(south_sd, 2), \"\\n\")\ncat(\"Ratio:\", round(max(north_sd, south_sd) / min(north_sd, south_sd), 2), \"\\n\")\n```\n\n### Python\n\n```{python ex5-variance-py}\n# Levene's test for equality of variances\nlevene_stat, levene_p = stats.levene(north_data, south_data)\nprint(f\"Levene's test p-value: {levene_p:.3f}\")\n\nif levene_p > 0.05:\n    print(\"Interpretation: No evidence of unequal variances (p > 0.05) - use standard t-test\")\nelse:\n    print(\"Interpretation: Evidence of unequal variances (p < 0.05) - use Welch's t-test\")\n\n# Compare standard deviations\nnorth_sd = north_data.std()\nsouth_sd = south_data.std()\nprint(f\"\\nNorth SD: {north_sd:.2f}\")\nprint(f\"South SD: {south_sd:.2f}\")\nprint(f\"Ratio: {max(north_sd, south_sd) / min(north_sd, south_sd):.2f}\")\n```\n\n:::\n\n**Assessment**:\n- Both distributions approximately normal\n- Variances appear equal (Levene's test p > 0.05)\n- Can proceed with standard two-sample t-test\n\n---\n\n## Step 4: Two-Sample t-test\n\n**Purpose**: Test if there's a significant difference between regions.\n\n---\n\n::: {.panel-tabset}\n\n### R\n\n```{r ex5-ttest-r}\n# Two-sample t-test (assuming equal variances)\nt_result <- t.test(ae_performance ~ ics, data = ae_data, var.equal = TRUE)\nprint(t_result)\n\n# Effect size (Cohen's d)\nnorth_mean <- mean(ae_data$ae_performance[ae_data$ics == \"North\"])\nsouth_mean <- mean(ae_data$ae_performance[ae_data$ics == \"South\"])\nn_north <- sum(ae_data$ics == \"North\")\nn_south <- sum(ae_data$ics == \"South\")\npooled_sd <- sqrt(((n_north - 1) * north_sd^2 + (n_south - 1) * south_sd^2) / \n                  (n_north + n_south - 2))\ncohens_d <- (north_mean - south_mean) / pooled_sd\n\ncat(\"\\nEffect size (Cohen's d):\", round(cohens_d, 2), \"\\n\")\ncat(\"Interpretation:\", \n    ifelse(abs(cohens_d) < 0.2, \"Negligible\",\n    ifelse(abs(cohens_d) < 0.5, \"Small\",\n    ifelse(abs(cohens_d) < 0.8, \"Medium\", \"Large\"))), \"\\n\")\n\ncat(\"\\nMean difference:\", round(north_mean - south_mean, 2), \"percentage points\\n\")\ncat(\"95% CI for difference: [\", round(t_result$conf.int[1], 2), \",\", \n    round(t_result$conf.int[2], 2), \"]\\n\")\n```\n\n### Python\n\n```{python ex5-ttest-py}\n# Two-sample t-test (assuming equal variances)\nt_stat, p_value = stats.ttest_ind(north_data, south_data, equal_var=True)\n\nprint(f\"Two-sample t-test results:\")\nprint(f\"t-statistic: {t_stat:.3f}\")\nprint(f\"p-value: {p_value:.4f}\")\n\n# Effect size (Cohen's d)\nnorth_mean = north_data.mean()\nsouth_mean = south_data.mean()\npooled_sd = np.sqrt(((len(north_data) - 1) * north_sd**2 + (len(south_data) - 1) * south_sd**2) / \n                    (len(north_data) + len(south_data) - 2))\ncohens_d = (north_mean - south_mean) / pooled_sd\n\nprint(f\"\\nEffect size (Cohen's d): {cohens_d:.2f}\")\nif abs(cohens_d) < 0.2:\n    interpretation = \"Negligible\"\nelif abs(cohens_d) < 0.5:\n    interpretation = \"Small\"\nelif abs(cohens_d) < 0.8:\n    interpretation = \"Medium\"\nelse:\n    interpretation = \"Large\"\nprint(f\"Interpretation: {interpretation}\")\n\nprint(f\"\\nMean difference: {north_mean - south_mean:.2f} percentage points\")\n\n# 95% CI for difference\nse_diff = pooled_sd * np.sqrt(1/len(north_data) + 1/len(south_data))\nci = stats.t.interval(0.95, len(north_data) + len(south_data) - 2,\n                      loc=north_mean - south_mean, scale=se_diff)\nprint(f\"95% CI for difference: [{ci[0]:.2f}, {ci[1]:.2f}]\")\n```\n\n:::\n\n**Results**:\n- Statistically significant difference (p < 0.05)\n- North Region performs ~3 percentage points better\n- Small-to-medium effect size\n- Difference is consistent (CI doesn't include zero)\n\n---\n\n## Step 5: Explore Confounding\n\n**Purpose**: Check if deprivation explains the regional difference.\n\n---\n\n::: {.panel-tabset}\n\n### R\n\n```{r ex5-confounding-r}\n# Check if deprivation differs between regions\ndeprivation_by_region <- aggregate(deprivation_score ~ ics, data = ae_data, \n                                   FUN = function(x) round(mean(x), 2))\nprint(deprivation_by_region)\n\n# Correlation between deprivation and performance\ncor_test <- cor.test(ae_data$deprivation_score, ae_data$ae_performance)\ncat(\"\\nCorrelation between deprivation and performance:\", \n    round(cor_test$estimate, 2), \"\\n\")\ncat(\"p-value:\", format.pval(cor_test$p.value), \"\\n\")\n\n# Scatter plot\nggplot(ae_data, aes(x = deprivation_score, y = ae_performance, color = ics)) +\n  geom_point(alpha = 0.6) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  scale_color_manual(values = c(\"North\" = \"steelblue\", \"South\" = \"coral\")) +\n  labs(\n    title = \"A&E Performance vs Deprivation by Region\",\n    x = \"Deprivation Score (higher = more deprived)\",\n    y = \"% Seen Within 4 Hours\",\n    color = \"Region\"\n  ) +\n  theme_minimal()\n```\n\n### Python\n\n```{python ex5-confounding-py}\n# Check if deprivation differs between regions\ndeprivation_by_region = ae_data.groupby('ics')['deprivation_score'].mean()\nprint(\"Mean deprivation by region:\")\nprint(deprivation_by_region)\n\n# Correlation between deprivation and performance\ncorr, p_value_corr = stats.pearsonr(ae_data['deprivation_score'], ae_data['ae_performance'])\nprint(f\"\\nCorrelation between deprivation and performance: {corr:.2f}\")\nprint(f\"p-value: {p_value_corr:.4f}\")\n\n# Scatter plot\nplt.figure(figsize=(10, 6))\nfor ics_name, color in [('North', 'steelblue'), ('South', 'coral')]:\n    data_subset = ae_data[ae_data['ics'] == ics_name]\n    plt.scatter(data_subset['deprivation_score'], data_subset['ae_performance'], \n                alpha=0.6, label=ics_name, color=color)\n    # Add trend line\n    z = np.polyfit(data_subset['deprivation_score'], data_subset['ae_performance'], 1)\n    p = np.poly1d(z)\n    plt.plot(data_subset['deprivation_score'].sort_values(), \n             p(data_subset['deprivation_score'].sort_values()), \n             color=color, linestyle='--')\n\nplt.xlabel('Deprivation Score (higher = more deprived)')\nplt.ylabel('% Seen Within 4 Hours')\nplt.title('A&E Performance vs Deprivation by Region')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n```\n\n:::\n\n**Findings**:\n- Deprivation similar in both regions\n- Negative correlation: more deprived areas have worse performance\n- Regional difference persists after accounting for deprivation\n\n---\n\n## Step 6: Conclusion\n\n**Statistical Conclusion**:\n- Significant difference between regions (p < 0.05)\n- North Region performs ~3 percentage points better\n- Small-to-medium effect size (Cohen's d â‰ˆ 0.4-0.6)\n- Difference not explained by deprivation\n\n**Practical Significance**:\n- 3 percentage point difference = ~360 more patients seen within 4 hours per trust per month\n- Across 100 trusts: ~36,000 patients per month\n- Clinically and operationally meaningful\n\n**Limitations**:\n- Cross-sectional comparison (not causal)\n- Other confounders not measured (staffing, facilities, case-mix)\n- Within-region variation is large\n- Both regions well below 95% target\n\n**Recommendations**:\n1. **Investigate North Region practices** - what drives better performance?\n2. **Share best practices** from North to South Region\n3. **Focus on within-region variation** - some South trusts perform as well as North\n4. **Consider additional factors** - staffing, resources, patient acuity\n5. **Monitor trends over time** - is the gap widening or narrowing?\n\n---\n\n**Analysis Complete** âœ…\n\n---\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":true,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../custom.css"],"toc":true,"toc-depth":3,"number-sections":false,"output-file":"example-05-complete.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.1.251","bibliography":["../references.bib"],"theme":"cosmo","number-depth":2,"title":"Example 5: Regional A&E Performance","subtitle":"Two-Sample t-test"},"extensions":{"book":{"multiFile":true}}}}}