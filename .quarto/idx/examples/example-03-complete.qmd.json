{"title":"Example 3: Mental Health Wait Times","markdown":{"yaml":{"title":"Example 3: Mental Health Wait Times","subtitle":"Z-scoring with Skewed Data","number-sections":false},"headingText":"| include: false","containsRefs":false,"markdown":"\n\n```{r}\n# Setup Python environment\nlibrary(reticulate)\n```\n\n## Scenario Overview\n\n**Method**: Z-scoring with transformation (@sec-z-scoring)  \n**Complexity**: Medium-High  \n**Time to complete**: 2-3 hours  \n**Status**: âœ… Complete\n\n::: {.callout-note icon=false}\n## ðŸ“– Method Reference\nFor detailed explanation of z-scoring methodology, handling skewed data, and step-by-step guidance, see @sec-z-scoring.\n:::\n\n---\n\n## ðŸ“‹ Scenario\n\nYou are analyzing wait times from assessment to treatment across 150 community mental health services using the 2024 Community Mental Health Survey. Most services have wait times under 3 months, but some have waits exceeding 6 months, creating a highly skewed distribution.\n\n**Analytical Question**: Which mental health services have wait times that are statistically significantly worse than the national average, accounting for the skewed distribution?\n\n**Context**: Mental health wait times are a key quality indicator. The data shows substantial right skew - most services perform well, but a minority have very long waits. Standard z-scoring assumes normality, which may not hold here.\n\n---\n\n## ðŸŽ¯ Learning Objectives\n\nBy working through this example, you will learn to:\n\n1. **Identify non-normal distributions** through visual and statistical checks\n2. **Understand when z-scoring assumptions fail** and why it matters\n3. **Apply data transformations** (log transformation) to reduce skew\n4. **Compare approaches**: raw z-scores vs transformed z-scores\n5. **Interpret results** when assumptions are violated\n6. **Conduct sensitivity analysis** to assess robustness\n7. **Communicate findings** about skewed data to stakeholders\n8. **Document analytical decisions** when methods require adaptation\n\n---\n\n## ðŸ“Š Dataset Description\n\n### Synthetic Data: `data/mental_health_wait_times.csv`\n\n**150 mental health services** with the following variables:\n\n| Variable | Description | Type | Notes |\n|----------|-------------|------|-------|\n| `service_code` | Unique service identifier | String | Format: MHS001-MHS150 |\n| `service_name` | Service name | String | Synthetic names |\n| `trust_name` | NHS Trust | String | 50 trusts |\n| `region` | NHS England region | String | 7 regions |\n| `wait_time_days` | Median wait time (days) | Integer | 30-250 days |\n| `survey_responses` | Survey respondents | Integer | 50-300 |\n| `deprivation_score` | Area deprivation (IMD) | Float | 10-40 |\n\n### Data Characteristics\n\n**Realistic issues included**:\n- Strong positive skew (right tail)\n- Most services 60-90 days, some >180 days\n- No missing data (complete survey)\n- Variation in survey response rates\n- Deprivation correlation (more deprived = longer waits)\n\n**Data generation**: Synthetic data generated using R (`set.seed(42)` for reproducibility). The data uses log-normal distribution to create realistic right skew. Both R and Python load the same CSV file, ensuring identical results.\n\n---\n\n## Step 1: Data Preparation\n\n**Purpose**: Load and prepare mental health wait times data with realistic skew.\n\n**Key tasks**:\n1. Generate synthetic data with skewed distribution\n2. Check data structure\n3. Explore distribution characteristics\n\n---\n\n::: {.panel-tabset}\n\n### R\n\n```{r ex3-generate-r}\n#| message: false\n#| warning: false\n\nlibrary(ggplot2)\n\n# Import mental health wait times data\nmh_data <- read.csv(\"data/mental_health_wait_times.csv\", stringsAsFactors = FALSE)\n\n# Display first few rows\nhead(mh_data)\n\n# Summary\nsummary(mh_data$wait_time_days)\n```\n\n### Python\n\n```{python ex3-generate-py}\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\n\n# Import mental health wait times data\nmh_data = pd.read_csv(\"data/mental_health_wait_times.csv\")\n\n# Display first few rows\nprint(mh_data.head())\n\n# Summary\nprint(mh_data['wait_time_days'].describe())\n```\n\n:::\n\n**Initial observations**:\n- Dataset has 150 mental health services\n- Wait times range from 30 to 215 days\n- Mean (79.8 days) > Median (71.5 days) suggests positive skew\n\n---\n\n## Step 2: Assess Distribution\n\n**Purpose**: Determine if data is suitable for standard z-scoring.\n\n---\n\n### Visualize Distribution\n\n::: {.panel-tabset}\n\n### R\n\n```{r ex3-hist-r}\n#| fig-width: 10\n#| fig-height: 6\n\nggplot(mh_data, aes(x = wait_time_days)) +\n  geom_histogram(bins = 30, fill = \"steelblue\", color = \"white\") +\n  geom_vline(xintercept = mean(mh_data$wait_time_days), \n             color = \"red\", linetype = \"dashed\", size = 1) +\n  geom_vline(xintercept = median(mh_data$wait_time_days), \n             color = \"blue\", linetype = \"dashed\", size = 1) +\n  labs(\n    title = \"Distribution of Mental Health Wait Times\",\n    subtitle = paste(\"Mean =\", round(mean(mh_data$wait_time_days), 1), \n                    \"days | Median =\", round(median(mh_data$wait_time_days), 1), \"days\"),\n    x = \"Wait Time (days)\",\n    y = \"Number of Services\"\n  ) +\n  theme_minimal()\n```\n\n### Python\n\n```{python ex3-hist-py}\nplt.figure(figsize=(10, 6))\nplt.hist(mh_data['wait_time_days'], bins=30, color='steelblue', edgecolor='white')\nplt.axvline(mh_data['wait_time_days'].mean(), color='red', linestyle='--', linewidth=2, label='Mean')\nplt.axvline(mh_data['wait_time_days'].median(), color='blue', linestyle='--', linewidth=2, label='Median')\nplt.xlabel('Wait Time (days)')\nplt.ylabel('Number of Services')\nplt.title(f\"Distribution of Mental Health Wait Times\\nMean = {mh_data['wait_time_days'].mean():.1f} days | Median = {mh_data['wait_time_days'].median():.1f} days\")\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n```\n\n:::\n\n**Observations**:\n- Clear positive skew (right tail)\n- Mean > Median (indicates skewness)\n- Most services cluster 60-90 days\n- Long tail extends to 200+ days\n\n---\n\n### Check Skewness Statistically\n\n::: {.panel-tabset}\n\n### R\n\n```{r ex3-skew-r}\nlibrary(e1071)\n\nskewness_value <- skewness(mh_data$wait_time_days)\ncat(\"Skewness:\", round(skewness_value, 2), \"\\n\")\ncat(\"Interpretation:\", \n    ifelse(abs(skewness_value) < 0.5, \"Approximately symmetric\",\n    ifelse(skewness_value > 1, \"Substantially positively skewed\",\n    ifelse(skewness_value < -1, \"Substantially negatively skewed\",\n           \"Moderately skewed\"))), \"\\n\")\n\n# Q-Q plot\nggplot(mh_data, aes(sample = wait_time_days)) +\n  stat_qq() +\n  stat_qq_line(color = \"red\") +\n  labs(\n    title = \"Q-Q Plot: Wait Times vs Normal Distribution\",\n    x = \"Theoretical Quantiles\",\n    y = \"Sample Quantiles\"\n  ) +\n  theme_minimal()\n```\n\n### Python\n\n```{python ex3-skew-py}\nfrom scipy.stats import skew\n\nskewness_value = skew(mh_data['wait_time_days'])\nprint(f\"Skewness: {skewness_value:.2f}\")\n\nif abs(skewness_value) < 0.5:\n    interpretation = \"Approximately symmetric\"\nelif skewness_value > 1:\n    interpretation = \"Substantially positively skewed\"\nelif skewness_value < -1:\n    interpretation = \"Substantially negatively skewed\"\nelse:\n    interpretation = \"Moderately skewed\"\n    \nprint(f\"Interpretation: {interpretation}\")\n\n# Q-Q plot\nfig, ax = plt.subplots(figsize=(8, 8))\nstats.probplot(mh_data['wait_time_days'], dist=\"norm\", plot=ax)\nax.set_title(\"Q-Q Plot: Wait Times vs Normal Distribution\")\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n```\n\n:::\n\n**Assessment**: \n- Skewness > 1 indicates substantial positive skew\n- Q-Q plot shows departure from normality in right tail\n- Standard z-scoring assumptions are violated\n\n**Decision**: Compare three approaches:\n1. Raw z-scores (despite skewness)\n2. Log-transformed z-scores\n3. Rank-based approach (percentiles)\n\n---\n\n## Step 3: Approach 1 - Raw Z-scores\n\n**Purpose**: Calculate standard z-scores despite skewness to see the impact.\n\n---\n\n::: {.panel-tabset}\n\n### R\n\n```{r ex3-raw-z-r}\n# Calculate raw z-scores\nmh_data$z_score_raw <- scale(mh_data$wait_time_days)[,1]\n\n# Assign bands\nmh_data$band_raw <- cut(mh_data$z_score_raw,\n                        breaks = c(-Inf, -2, -1, 1, 2, Inf),\n                        labels = c(\"Much Better\", \"Better\", \"As Expected\", \n                                  \"Worse\", \"Much Worse\"))\n\n# Summary\ntable(mh_data$band_raw)\n\n# Flag services in worst band\nflagged_raw <- mh_data[mh_data$band_raw == \"Much Worse\", ]\ncat(\"\\nServices flagged (raw z-scores):\", nrow(flagged_raw), \"\\n\")\n```\n\n### Python\n\n```{python ex3-raw-z-py}\n# Calculate raw z-scores\nmh_data['z_score_raw'] = (mh_data['wait_time_days'] - mh_data['wait_time_days'].mean()) / mh_data['wait_time_days'].std()\n\n# Assign bands\nmh_data['band_raw'] = pd.cut(mh_data['z_score_raw'],\n                              bins=[-np.inf, -2, -1, 1, 2, np.inf],\n                              labels=[\"Much Better\", \"Better\", \"As Expected\", \n                                     \"Worse\", \"Much Worse\"])\n\n# Summary\nprint(mh_data['band_raw'].value_counts().sort_index())\n\n# Flag services in worst band\nflagged_raw = mh_data[mh_data['band_raw'] == \"Much Worse\"]\nprint(f\"\\nServices flagged (raw z-scores): {len(flagged_raw)}\")\n```\n\n:::\n\n---\n\n## Step 4: Approach 2 - Log-Transformed Z-scores\n\n**Purpose**: Apply log transformation to reduce skew, then calculate z-scores.\n\n---\n\n::: {.panel-tabset}\n\n### R\n\n```{r ex3-log-z-r}\n# Log transform wait times\nmh_data$log_wait_time <- log(mh_data$wait_time_days)\n\n# Calculate z-scores on log scale\nmh_data$z_score_log <- scale(mh_data$log_wait_time)[,1]\n\n# Assign bands\nmh_data$band_log <- cut(mh_data$z_score_log,\n                        breaks = c(-Inf, -2, -1, 1, 2, Inf),\n                        labels = c(\"Much Better\", \"Better\", \"As Expected\", \n                                  \"Worse\", \"Much Worse\"))\n\n# Summary\ntable(mh_data$band_log)\n\n# Flag services in worst band\nflagged_log <- mh_data[mh_data$band_log == \"Much Worse\", ]\ncat(\"\\nServices flagged (log z-scores):\", nrow(flagged_log), \"\\n\")\n\n# Check distribution of log-transformed data\nggplot(mh_data, aes(x = log_wait_time)) +\n  geom_histogram(bins = 30, fill = \"steelblue\", color = \"white\") +\n  labs(\n    title = \"Distribution of Log-Transformed Wait Times\",\n    subtitle = \"More symmetric after transformation\",\n    x = \"Log(Wait Time)\",\n    y = \"Number of Services\"\n  ) +\n  theme_minimal()\n```\n\n### Python\n\n```{python ex3-log-z-py}\n# Log transform wait times\nmh_data['log_wait_time'] = np.log(mh_data['wait_time_days'])\n\n# Calculate z-scores on log scale\nmh_data['z_score_log'] = (mh_data['log_wait_time'] - mh_data['log_wait_time'].mean()) / mh_data['log_wait_time'].std()\n\n# Assign bands\nmh_data['band_log'] = pd.cut(mh_data['z_score_log'],\n                              bins=[-np.inf, -2, -1, 1, 2, np.inf],\n                              labels=[\"Much Better\", \"Better\", \"As Expected\", \n                                     \"Worse\", \"Much Worse\"])\n\n# Summary\nprint(mh_data['band_log'].value_counts().sort_index())\n\n# Flag services in worst band\nflagged_log = mh_data[mh_data['band_log'] == \"Much Worse\"]\nprint(f\"\\nServices flagged (log z-scores): {len(flagged_log)}\")\n\n# Check distribution of log-transformed data\nplt.figure(figsize=(10, 6))\nplt.hist(mh_data['log_wait_time'], bins=30, color='steelblue', edgecolor='white')\nplt.xlabel('Log(Wait Time)')\nplt.ylabel('Number of Services')\nplt.title('Distribution of Log-Transformed Wait Times\\nMore symmetric after transformation')\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n```\n\n:::\n\n**Observations**:\n- Log transformation reduces skewness\n- Distribution closer to normal\n- Different services may be flagged compared to raw approach\n\n---\n\n## Step 5: Compare Approaches\n\n**Purpose**: Assess sensitivity of results to methodological choice.\n\n---\n\n::: {.panel-tabset}\n\n### R\n\n```{r ex3-compare-r}\n# Compare flagged services\nraw_codes <- mh_data$service_code[mh_data$band_raw == \"Much Worse\"]\nlog_codes <- mh_data$service_code[mh_data$band_log == \"Much Worse\"]\n\n# Agreement\nagreement <- length(intersect(raw_codes, log_codes))\nraw_only <- length(setdiff(raw_codes, log_codes))\nlog_only <- length(setdiff(log_codes, raw_codes))\n\ncat(\"Services flagged by both methods:\", agreement, \"\\n\")\ncat(\"Flagged by raw z-scores only:\", raw_only, \"\\n\")\ncat(\"Flagged by log z-scores only:\", log_only, \"\\n\")\ncat(\"Agreement rate:\", round(100 * agreement / max(length(raw_codes), length(log_codes)), 1), \"%\\n\")\n\n# Scatter plot comparing approaches\nggplot(mh_data, aes(x = z_score_raw, y = z_score_log)) +\n  geom_point(alpha = 0.6) +\n  geom_hline(yintercept = 2, color = \"red\", linetype = \"dashed\") +\n  geom_vline(xintercept = 2, color = \"red\", linetype = \"dashed\") +\n  labs(\n    title = \"Comparison of Raw vs Log-Transformed Z-scores\",\n    subtitle = \"Dashed lines show flagging threshold (z > 2)\",\n    x = \"Raw Z-score\",\n    y = \"Log-Transformed Z-score\"\n  ) +\n  theme_minimal()\n```\n\n### Python\n\n```{python ex3-compare-py}\n# Compare flagged services\nraw_codes = set(mh_data[mh_data['band_raw'] == \"Much Worse\"]['service_code'])\nlog_codes = set(mh_data[mh_data['band_log'] == \"Much Worse\"]['service_code'])\n\n# Agreement\nagreement = len(raw_codes & log_codes)\nraw_only = len(raw_codes - log_codes)\nlog_only = len(log_codes - raw_codes)\n\nprint(f\"Services flagged by both methods: {agreement}\")\nprint(f\"Flagged by raw z-scores only: {raw_only}\")\nprint(f\"Flagged by log z-scores only: {log_only}\")\nprint(f\"Agreement rate: {100 * agreement / max(len(raw_codes), len(log_codes)):.1f}%\")\n\n# Scatter plot comparing approaches\nplt.figure(figsize=(10, 8))\nplt.scatter(mh_data['z_score_raw'], mh_data['z_score_log'], alpha=0.6)\nplt.axhline(y=2, color='red', linestyle='--', label='Flagging threshold')\nplt.axvline(x=2, color='red', linestyle='--')\nplt.xlabel('Raw Z-score')\nplt.ylabel('Log-Transformed Z-score')\nplt.title('Comparison of Raw vs Log-Transformed Z-scores\\nDashed lines show flagging threshold (z > 2)')\nplt.grid(True, alpha=0.3)\nplt.legend()\nplt.tight_layout()\nplt.show()\n```\n\n:::\n\n---\n\n## Step 6: Recommendation\n\n**Purpose**: Document analytical decision and rationale.\n\n---\n\n**Decision**: Use log-transformed z-scores for final analysis.\n\n**Rationale**:\n1. **Assumption validity**: Log transformation brings data closer to normality\n2. **Statistical appropriateness**: Z-scoring assumes normal distribution\n3. **Reduced sensitivity to outliers**: Extreme values have less influence\n4. **Interpretability**: Can back-transform for reporting\n\n**Caveats**:\n- Log transformation changes the metric (multiplicative vs additive differences)\n- Services near threshold may differ between methods\n- Document both approaches in QA log\n\n**Communication**: Report wait times in original scale (days) but use log-transformed z-scores for statistical comparison.\n\n---\n\n## Step 7: Final Results\n\n::: {.panel-tabset}\n\n### R\n\n```{r ex3-final-r}\n# Services requiring follow-up (log z-score approach)\nflagged_final <- mh_data[mh_data$band_log %in% c(\"Worse\", \"Much Worse\"), \n                         c(\"service_code\", \"service_name\", \"wait_time_days\", \n                           \"z_score_log\", \"band_log\")]\n\nflagged_final <- flagged_final[order(-flagged_final$z_score_log), ]\n\ncat(\"Services flagged for follow-up:\", nrow(flagged_final), \"\\n\")\ncat(\"Percentage of total:\", round(100 * nrow(flagged_final) / nrow(mh_data), 1), \"%\\n\\n\")\n\n# Top 10\nhead(flagged_final, 10)\n```\n\n### Python\n\n```{python ex3-final-py}\n# Services requiring follow-up (log z-score approach)\nflagged_final = mh_data[mh_data['band_log'].isin([\"Worse\", \"Much Worse\"])][\n    ['service_code', 'service_name', 'wait_time_days', 'z_score_log', 'band_log']\n].sort_values('z_score_log', ascending=False)\n\nprint(f\"Services flagged for follow-up: {len(flagged_final)}\")\nprint(f\"Percentage of total: {100 * len(flagged_final) / len(mh_data):.1f}%\\n\")\n\n# Top 10\nprint(flagged_final.head(10))\n```\n\n:::\n\n---\n\n**Analysis Complete** âœ…\n\n**Key Takeaways**:\n1. Always check distribution assumptions before applying z-scoring\n2. Skewed data can be handled with transformation\n3. Compare multiple approaches for sensitivity\n4. Document methodological decisions\n5. Report results in interpretable units\n\n---\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":true,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../custom.css"],"toc":true,"toc-depth":3,"number-sections":false,"output-file":"example-03-complete.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.1.251","bibliography":["../references.bib"],"theme":"cosmo","number-depth":2,"title":"Example 3: Mental Health Wait Times","subtitle":"Z-scoring with Skewed Data"},"extensions":{"book":{"multiFile":true}}}}}