---
title: "Monitoring Trends Over Time: SPC Basics"
---

```{r}
#| include: false
# Setup Python environment
library(reticulate)
use_python("C:/Users/fede/anaconda3/python.exe", required = TRUE)
```

::: {.callout-tip icon=false}
## Problem This Method Solves

You need to monitor whether something is changing over time and distinguish real changes from random noise. For example:

- Are monthly incident rates at a care home genuinely increasing, or just normal variation?
- Has a quality improvement intervention actually worked, or are we seeing random fluctuation?
- When did performance start to deteriorate, and when did it improve?

Statistical Process Control (SPC) methods help you detect genuine changes earlier while avoiding false alarms from random variation.
:::

## What SPC Does {#sec-spc-basics}

SPC monitors processes over time to distinguish **common cause variation** (normal, expected fluctuation) from **special cause variation** (genuine changes that warrant investigation).

**Key purpose**: SPC is about **understanding process behavior** (analytic study), not estimating population parameters (enumerative study). You're asking "is this process stable or changing?" not "what's the population mean?"

**Key advantages**:
- Detects changes earlier than waiting for annual comparisons
- Reduces false alarms by accounting for natural variation
- Provides visual, intuitive displays
- Supports real-time monitoring and rapid response
- Helps understand process capability and variation patterns

**What it does NOT do**:
- Explain why changes occurred (investigation determines cause)
- Replace professional judgment about whether to act
- Work well with very small sample sizes or infrequent measurements
- Provide formal statistical inference (p-values, confidence intervals)

## Common Cause vs Special Cause Variation

**Common cause variation** (random, expected):
- Natural fluctuation in any process
- Predictable range even though individual values vary
- No specific assignable cause
- Example: Monthly incident counts varying between 8-12 when average is 10

**Special cause variation** (signal of change):
- Unusual pattern outside expected range
- Indicates something has changed in the process
- Has an assignable cause worth investigating
- Example: Incident counts suddenly jumping to 18-20 per month

**SPC's value**: It quantifies "expected range" so you know when variation is unusual enough to investigate.

## Before You Start

::: {.callout-note icon=false}
## Note on Code Examples
The worked examples in this chapter use pseudo-randomly generated data to illustrate the methods. To ensure consistent results between R and Python, the Python code uses the same dataset generated by R (via `r.data_name`). The commented-out Python code shows how you would generate equivalent data independently if needed.
:::

Check these requirements before applying SPC:

### Data Requirements
- [ ] **Time-ordered data**: Measurements taken sequentially over time
- [ ] **Sufficient data points**: At least 12-20 time points for reliable limits
- [ ] **Consistent measurement**: Same definition and method throughout
- [ ] **Regular intervals**: Ideally consistent time periods (weekly, monthly, quarterly)
- [ ] **Quality checks**: Completed pre-analysis QA (see @sec-qa-principles)

### When SPC May Not Be Appropriate
- **Too few time points** (<12): Can't establish reliable control limits
- **Irregular measurements**: Long gaps or inconsistent intervals make interpretation difficult
- **Changing definitions**: If what you're measuring changes, you can't track it over time
- **Cross-sectional comparison**: Use z-scoring (@sec-z-scoring) for comparing providers at one time point

### What You Need
- Time-series data (dates and values)
- Understanding of what you're measuring and why
- Statistical software (R recommended, examples provided)

::: {.callout-note icon=false}
## ðŸ“– Complete Worked Examples

**Example 2: Care Home Falls Monitoring** demonstrates SPC with realistic CQC data:

- Setting up control charts from scratch
- Calculating control limits correctly (I-chart method)
- Detecting intervention effects using SPC rules
- Handling special causes (flu outbreak month)
- Assessing sustainability of improvements

**Time**: 2-3 hours | **Complexity**: Medium

[View Example 2: Care Home Falls SPC â†’](../examples/example-02-complete.qmd)

**Example 6: Ambulance Handover Delays** demonstrates SPC with trend analysis:

- Monitoring time-series data with trends
- Handling seasonal patterns
- Distinguishing trends from special causes
- Interpreting complex SPC patterns

**Time**: 2-3 hours | **Complexity**: Medium-High

[View Example 6: Ambulance Handover Delays â†’](../examples/example-06-complete.qmd)
:::

## Understanding Control Charts

A **control chart** plots your data over time with three key lines:

**Centre line**: The process average (mean)

**Upper Control Limit (UCL)**: Upper boundary of expected variation (typically mean + 3 SD)

**Lower Control Limit (LCL)**: Lower boundary of expected variation (typically mean - 3 SD)

**Interpretation**:
- Points within control limits: Common cause variation (expected)
- Points outside control limits: Special cause variation (investigate)
- Patterns within limits: May also signal change (see detection rules)

**Why 3 standard deviations?** With normally distributed data, 99.8% of points should fall within Â±3 SD. A point outside this range is very unlikely to be random chance (0.2% probability).

## Types of Control Charts

Different data types need different charts:

### I-Chart (Individuals Chart)
**Use for**: Continuous data, one measurement per time period

**Example**: Monthly average waiting time, quarterly mean length of stay

**Control limits**: 
- Centre line = mean of all observations
- UCL = mean + 3 Ã— moving range average / 1.128
- LCL = mean - 3 Ã— moving range average / 1.128

**When to use**: Most versatile chart for continuous measures

### P-Chart (Proportion Chart)
**Use for**: Proportions or percentages

**Example**: Percentage of patients seen within target, proportion of incidents that are serious

**Control limits**: Based on binomial distribution, vary with sample size

**When to use**: When tracking rates or percentages over time

### C-Chart (Count Chart)
**Use for**: Counts of events when opportunity is constant

**Example**: Number of incidents per month (if bed days roughly constant), number of complaints per quarter

**Control limits**: Based on Poisson distribution

**When to use**: Counting rare events with stable denominator

### U-Chart (Rate Chart)
**Use for**: Rates when opportunity varies

**Example**: Incidents per 1,000 bed days (when bed days change month to month)

**Control limits**: Based on Poisson distribution, vary with denominator

**When to use**: Like C-chart but when denominator changes

## Step-by-Step Guide: I-Chart

I'll demonstrate with an I-chart (most common). Other chart types follow similar logic with different limit calculations.

### Step 1: Plot Your Data Over Time

Create a time-series plot showing your data points connected by lines. This helps you:
- Visualize trends over time
- Spot obvious patterns or shifts
- Identify potential outliers
- Assess whether the process looks stable

### Step 2: Calculate Centre Line and Control Limits

For I-chart, calculate:

**Centre line (CL)**: Mean of all data points
$$\text{CL} = \bar{x} = \frac{\sum x_i}{n}$$

**Moving range (MR)**: Absolute difference between consecutive points
$$\text{MR}_i = |x_i - x_{i-1}|$$

**Average moving range**: 
$$\overline{\text{MR}} = \frac{\sum \text{MR}_i}{n-1}$$

**Control limits**:
$$\text{UCL} = \bar{x} + 3 \times \frac{\overline{\text{MR}}}{1.128}$$
$$\text{LCL} = \bar{x} - 3 \times \frac{\overline{\text{MR}}}{1.128}$$

The constant 1.128 is used to estimate standard deviation from moving range for individuals charts.

### Step 3: Add Control Limits to Chart

Plot your time-series data with three horizontal lines:
- **Centre line** (blue, solid): The process mean
- **UCL** (red, dashed): Upper control limit
- **LCL** (red, dashed): Lower control limit

Highlight any points that fall outside the control limits in red - these indicate special cause variation requiring investigation.

### Step 4: Apply Detection Rules

Beyond points outside control limits, watch for these patterns:

**Rule 1**: One point beyond control limits (3 sigma)

**Rule 2**: Two out of three consecutive points beyond 2 sigma (warning limits)

**Rule 3**: Four out of five consecutive points beyond 1 sigma

**Rule 4**: Eight consecutive points on one side of centre line (shift)

**Rule 5**: Six consecutive points all increasing or decreasing (trend)

These rules help detect changes before they become extreme.

### Step 5: Interpret and Act

**Points outside limits**: Investigate immediately. Something has changed.

**Patterns within limits**: May indicate gradual shift or trend. Consider investigation.

**Random scatter within limits**: Process is stable. No action needed.

## Worked Example: Care Home Monthly Incidents

**Scenario**: You're monitoring monthly incident counts at a care home. A new falls prevention program started in month 13. Did it work?

**Data**:

:::: {.panel-tabset}
## R
```{r}
#| label: spc-intervention-data
# Simulate realistic care home data (seed for reproducibility)
set.seed(42)
months <- 1:24
# Baseline: average 18 incidents/month, then reduction after intervention
baseline <- rpois(12, lambda = 18)
post_intervention <- rpois(12, lambda = 13)  # Reduced after intervention
incidents <- c(baseline, post_intervention)

data <- data.frame(
  month = months,
  incidents = incidents,
  phase = c(rep("Baseline", 12), rep("Post-intervention", 12))
)
```

## Python
```{python}
import pandas as pd
import numpy as np

# Use the same data from R for consistent results
data = r.data

# Alternative: Generate data in Python (commented out for consistency)
# np.random.seed(42)
# months = list(range(1, 25))
# baseline = np.random.poisson(18, 12)
# post_intervention = np.random.poisson(13, 12)
# incidents = np.concatenate([baseline, post_intervention])
# data = pd.DataFrame({
#     'month': months,
#     'incidents': incidents,
#     'phase': ['Baseline']*12 + ['Post-intervention']*12
# })
```
::::

**Analysis**:

:::: {.panel-tabset}
## R
```{r}
#| label: spc-intervention-chart
#| fig-width: 12
#| fig-height: 6
# Calculate control limits using baseline period only
baseline_data <- data$incidents[1:12]
centre_line <- mean(baseline_data)
mr <- abs(diff(baseline_data))
mr_bar <- mean(mr)
ucl <- centre_line + 3 * (mr_bar / 1.128)
lcl <- centre_line - 3 * (mr_bar / 1.128)

# Create control chart
plot(data$month, data$incidents, type = "b", pch = 19,
     col = ifelse(data$phase == "Baseline", "black", "darkgreen"),
     xlab = "Month", ylab = "Incident Count",
     main = "Care Home Incidents: Before and After Falls Prevention Program",
     ylim = c(0, max(ucl, data$incidents)))

# Add control limits (based on baseline)
abline(h = centre_line, col = "blue", lwd = 2)
abline(h = ucl, col = "red", lwd = 2, lty = 2)
abline(h = lcl, col = "red", lwd = 2, lty = 2)

# Mark intervention point
abline(v = 12.5, col = "purple", lwd = 2, lty = 3)
text(12.5, max(data$incidents), "Intervention", pos = 4, col = "purple")

# Highlight out-of-control points
outside <- data$incidents > ucl | data$incidents < lcl
points(data$month[outside], data$incidents[outside], 
       col = "red", pch = 19, cex = 2)

# Add legend
legend("topright", 
       legend = c("Baseline", "Post-intervention", "Centre", "Control Limits"),
       col = c("black", "darkgreen", "blue", "red"),
       lty = c(1, 1, 1, 2), pch = c(19, 19, NA, NA))
```

## Python
```{python}
import matplotlib.pyplot as plt

# Calculate control limits using baseline period only
baseline_data = data['incidents'][:12]
centre_line = baseline_data.mean()
mr = baseline_data.diff().abs()
mr_bar = mr.mean()
ucl = centre_line + 3 * (mr_bar / 1.128)
lcl = centre_line - 3 * (mr_bar / 1.128)

# Create control chart
plt.figure(figsize=(12, 6))
colors = ['black' if p == 'Baseline' else 'darkgreen' for p in data['phase']]
plt.plot(data['month'], data['incidents'], marker='o', linestyle='-', color='gray')
plt.scatter(data['month'], data['incidents'], c=colors, s=50, zorder=3)

# Add control limits (based on baseline)
plt.axhline(y=centre_line, color='blue', linewidth=2, label='Centre')
plt.axhline(y=ucl, color='red', linewidth=2, linestyle='--', label='Control Limits')
plt.axhline(y=lcl, color='red', linewidth=2, linestyle='--')

# Mark intervention point
plt.axvline(x=12.5, color='purple', linewidth=2, linestyle=':', label='Intervention')

# Highlight out-of-control points
outside = (data['incidents'] > ucl) | (data['incidents'] < lcl)
plt.scatter(data.loc[outside, 'month'], data.loc[outside, 'incidents'], 
           color='red', s=200, zorder=5, edgecolors='black', linewidths=2)

plt.xlabel('Month')
plt.ylabel('Incident Count')
plt.title('Care Home Incidents: Before and After Falls Prevention Program')
plt.ylim(0, max(ucl, data['incidents'].max()))
plt.legend()
plt.tight_layout()
plt.show()
```
::::

**Interpretation**:

:::: {.panel-tabset}
## R
```{r}
#| label: spc-interpretation
# Check if post-intervention points are outside baseline limits
post_outside <- data$incidents[13:24] < lcl | data$incidents[13:24] > ucl
cat("Points outside control limits post-intervention:", sum(post_outside), "\n")

# Calculate new mean post-intervention
post_mean <- mean(data$incidents[13:24])
cat("Baseline mean:", round(centre_line, 1), "\n")
cat("Post-intervention mean:", round(post_mean, 1), "\n")
cat("Reduction:", round(centre_line - post_mean, 1), "incidents/month\n")
```

## Python
```{python}
# Check if post-intervention points are outside baseline limits
post_outside = (data['incidents'][12:24] < lcl) | (data['incidents'][12:24] > ucl)
print(f"Points outside control limits post-intervention: {post_outside.sum()}")

# Calculate new mean post-intervention
post_mean = data['incidents'][12:24].mean()
print(f"Baseline mean: {centre_line:.1f}")
print(f"Post-intervention mean: {post_mean:.1f}")
print(f"Reduction: {centre_line - post_mean:.1f} incidents/month")
```
::::

**Conclusion**: If multiple post-intervention points fall below the LCL, this signals a genuine reduction in incidents. The intervention appears to have worked. You would then recalculate control limits using the new, lower baseline for ongoing monitoring.

## Choosing the Right Chart

Use this decision tree:

**What are you measuring?**

â†’ **Continuous data** (waiting times, length of stay, scores)
  - One measurement per period? â†’ **I-Chart**
  - Multiple measurements per period? â†’ **XÌ„-chart** (beyond this guide, consult Guild)

â†’ **Proportions/Percentages** (% meeting target, % with complications)
  - â†’ **P-Chart**

â†’ **Counts of events**
  - Opportunity constant (same denominator)? â†’ **C-Chart**
  - Opportunity varies (changing denominator)? â†’ **U-Chart**

**Still unsure?** I-charts are most versatile. Start there unless you have clear proportions or counts.

## Common Pitfalls

**Pitfall 1: Too few data points**
- Need at least 12-20 points to establish reliable limits
- With fewer points, limits are unstable and unreliable

**Pitfall 2: Recalculating limits too often**
- Control limits should be stable unless process fundamentally changes
- Don't recalculate every time you add a point, defeats the purpose

**Pitfall 3: Treating every point outside limits as a crisis**
- Even with stable process, 0.2% of points will be outside limits by chance
- Investigate, but don't panic. Confirm the change is real.

**Pitfall 4: Ignoring patterns within limits**
- Eight points on one side of centre = shift
- Six increasing points = trend
- These signal change even if within limits

**Pitfall 5: Using wrong chart type**
- Proportions need P-charts (not I-charts)
- Counts with varying denominators need U-charts (not C-charts)
- Wrong chart = wrong limits = wrong conclusions

## Documenting Your Analysis

For QA purposes, record:

**Data**:
- What you're measuring and why
- Time period covered
- Number of observations
- Any exclusions or data quality issues

**Chart specifications**:
- Chart type used and why
- How control limits were calculated
- What period was used to establish limits
- Any recalculation of limits and why

**Results**:
- Points outside control limits (when and how many)
- Patterns detected (shifts, trends)
- Whether process appears stable or changing

**Decisions**:
- What actions were triggered
- Why you did/didn't investigate specific points
- Any process changes implemented

::: {.callout-note icon=false}
## Rethinking: CQC's SPC Journey

SPC has been used in healthcare for decades, but CQC's adoption has been gradual. Why?

**Early challenges**:
- Perceived as complex and technical
- Required consistent time-series data (not always available)
- Analysts more familiar with cross-sectional comparison (z-scoring)
- Stakeholder preference for simple RAG ratings

**Growing adoption**:
- Real-time monitoring needs increased (can't wait for annual reviews)
- Quality improvement culture emphasizes process monitoring
- Better data systems enable time-series analysis
- Success stories from NHS trusts using SPC

**Current CQC use**:
- Monitoring trends in key indicators (emergency admissions, incidents)
- Evaluating impact of interventions
- Provider-level monitoring of their own performance
- Complementing cross-sectional z-scoring

**Lessons learned**:
- Start simple: I-charts and P-charts are sufficient for most needs
- Visual display matters: Control charts communicate better than tables
- Training is essential: SPC requires different thinking than cross-sectional methods
- Integration with QI: SPC works best when linked to improvement cycles

**Future direction**: More real-time monitoring, integration with provider dashboards, combining SPC with predictive analytics.

The key: SPC isn't replacing other methods, it's adding time-series capability to CQC's analytical toolkit.
:::

::: {.callout-warning icon=false}
## Overthinking: Detection Rules and Sensitivity

The basic rule (points outside 3-sigma limits) is conservative: it minimizes false alarms but may miss gradual changes. Additional **Western Electric rules** increase sensitivity:

**Rule 1**: One point beyond 3 sigma (standard)

**Rule 2**: Two out of three consecutive points beyond 2 sigma (same side)

**Rule 3**: Four out of five consecutive points beyond 1 sigma (same side)

**Rule 4**: Eight consecutive points on one side of centre line

**Rule 5**: Six consecutive points steadily increasing or decreasing

**Rule 6**: Fifteen consecutive points within 1 sigma (too stable, may indicate data manipulation)

**Trade-off**: More rules = earlier detection but more false alarms. Choose based on:
- Cost of false alarm vs cost of missing real change
- How quickly you need to detect change
- Stakeholder tolerance for investigation

**CQC context**: For high-stakes indicators (safety), use multiple rules. For routine monitoring, Rule 1 + Rule 4 may suffice.

**Implementation**:

:::: {.panel-tabset}
## R
```r
# Function to check Rule 4 (8 consecutive points one side)
check_rule4 <- function(values, centre) {
  above <- values > centre
  runs <- rle(above)
  any(runs$lengths >= 8)
}

# Apply to data
if(check_rule4(data$value, centre_line)) {
  cat("Warning: Rule 4 violated - sustained shift detected\n")
}
```

## Python
```python
import numpy as np

# Function to check Rule 4 (8 consecutive points one side)
def check_rule4(values, centre):
    above = values > centre
    # Find runs of consecutive True/False
    runs = []
    current_run = 1
    for i in range(1, len(above)):
        if above[i] == above[i-1]:
            current_run += 1
        else:
            runs.append(current_run)
            current_run = 1
    runs.append(current_run)
    return any(r >= 8 for r in runs)

# Apply to data
if check_rule4(data['value'], centre_line):
    print("Warning: Rule 4 violated - sustained shift detected")
```
::::

:::

::: {.callout-warning icon=false}
## Overthinking: Advanced SPC Methods

**CUSUM (Cumulative Sum) charts**: Plot cumulative deviations from target. More sensitive to small persistent shifts than Shewhart charts.

**Advantages**:
- Detects small changes faster
- Good for monitoring improvements
- Can be designed for specific shift sizes

**Disadvantages**:
- Less intuitive to interpret
- More complex to implement
- Harder to explain to stakeholders

**When to use**: When you need to detect small changes quickly (e.g., mortality monitoring, infection rates).

**EWMA (Exponentially Weighted Moving Average) charts**: Weighted average giving more weight to recent observations.

**Advantages**:
- Sensitive to small shifts
- Smooths out noise
- Good for autocorrelated data

**Disadvantages**:
- Requires choosing smoothing parameter
- Less intuitive than Shewhart
- Can lag behind rapid changes

**When to use**: When data is noisy or you need to detect gradual drifts.

**Bayesian SPC**: Uses Bayesian methods to update beliefs about process state as new data arrives.

**Advantages**:
- Incorporates prior knowledge
- Provides probability statements about change
- Handles small samples better

**Disadvantages**:
- Requires specialist expertise
- More computationally intensive
- Harder to explain

**When to use**: Research context or when you have strong prior information.

**CQC practice**: Stick with simple Shewhart-type charts (I, P, C, U) for most applications. Escalate to Guild for CUSUM, EWMA, or Bayesian methods. These advanced methods are referenced in the literature but rarely needed for routine monitoring.

**Key principle**: Simple methods consistently applied beat complex methods inconsistently used.
:::

::: {.callout-note icon=false}
## Rethinking: Evidence for SPC in Healthcare

A systematic review of SPC in healthcare (Thor et al., 2007) found substantial evidence of benefits:

**Process understanding benefits**:
- Helps distinguish common cause from special cause variation
- Provides visual, intuitive display of performance over time
- Enables real-time monitoring and rapid response
- Supports identification of improvement opportunities

**Organizational benefits**:
- Facilitates communication between clinicians and managers
- Empowers frontline staff to monitor their own processes
- Builds shared understanding of variation
- Supports data-driven decision making

**Patient benefits**:
- Enables patients to monitor their own health indicators (e.g., blood sugar, peak flow)
- Has therapeutic potential through patient empowerment
- Supports earlier detection of deterioration

**Key finding**: "Among the most powerful quality management tools...is statistical process control. Most notable among those tools are control charts. Under optimal conditions, these graphical depictions of process performance allow participants to know what is happening within their processes as 'real time' data enable them to make appropriate decisions." (Intermountain Healthcare)

**Limitations identified**:
- Requires adequate training and support
- Can be misapplied if assumptions not checked
- Needs organizational commitment to act on signals
- Not a substitute for understanding the process

**CQC context**: SPC works best when combined with process knowledge. Charts signal when to investigate, your regulatory expertise determines what the signal means.
:::

## Related Approaches

**For different analytical questions**:
- **Provider comparison** (not time trends) â†’ Z-scoring (@sec-z-scoring)
- **Two-group comparison** â†’ t-tests (@sec-t-tests) for before/after analysis
- **Trending data** â†’ See Example 6 (Ambulance Handovers) for SPC with trends
- **Policy intervention impact** â†’ See Example 8 (DoLS Trends) for interrupted time series

**For advanced SPC methods**:
- **CUSUM charts** â†’ See Overthinking box above, or consult Guild
- **EWMA charts** â†’ Guild consultation for implementation
- **Bayesian SPC** â†’ Specialist methods, Guild support required

**For foundational concepts**:
- **Understanding variation** â†’ @sec-variation-uncertainty (common vs special cause)
- **Data quality checks** â†’ @sec-qa-principles

**For complete workflows**:
- **Care Home Falls** â†’ Example 2 (SPC with intervention)
- **Ambulance Handovers** â†’ Example 6 (SPC with trend analysis)

## When to Escalate to the Guild

Escalate to the Quantitative Guild when:

- **Complex chart types needed**: G-charts, T-charts, or other specialized charts beyond basics
- **Autocorrelation suspected**: Data points are not independent (common in daily/weekly data)
- **Multiple concurrent changes**: Several interventions or changes happening simultaneously
- **Unusual patterns**: Chart shows patterns not covered by basic detection rules
- **Short-term vs long-term variation**: Need to separate different sources of variation
- **Risk-adjusted SPC**: Need to account for case-mix or other confounders
- **Bayesian SPC**: Stakeholders want probability statements rather than control limits
- **Phase analysis**: Complex questions about when changes occurred

## Key Takeaways

::: {.callout-important icon=false}
## Essential Points

1. **SPC distinguishes signal from noise** in time-series data
2. **Choose chart type based on data type**: I-chart for continuous, P-chart for proportions, C/U-chart for counts
3. **Need adequate data**: At least 12-20 points for reliable limits
4. **Points outside limits signal change**, but patterns within limits also matter
5. **Visual display is powerful**: Control charts communicate better than tables
6. **Complement, don't replace other methods**: Use with z-scoring for complete picture
7. **Start simple**: Basic charts work for most CQC applications

SPC is essential for monitoring change over time. Master the basics before considering advanced methods.
:::

## Further Reading

**Internal CQC Resources**:

- **QA Framework**: Documentation standards for SPC analyses
- **Guild Terms of Reference**: When and how to escalate for specialist support
- **CQC's SPC Journey** (Internal document): How CQC has adopted SPC methods

**External Guidance**:

- **Mohammed MA, Worthington P, Woodall WH** (2008). "Plotting basic control charts: tutorial notes for healthcare practitioners." *Quality and Safety in Health Care*, 17(2), 137-145. (Excellent practical introduction)
- **Provost LP, Murray SK** (2011). *The Health Care Data Guide: Learning from Data for Improvement*. Jossey-Bass. (Comprehensive textbook)
- **NHS Improvement SPC guidance**: https://www.england.nhs.uk/statistical-process-control-tool/
- **AQuA Book** (Chapter on Time Series): Analyzing data over time

**Online Resources**:

- Understanding SPC: https://www.spcforexcel.com/knowledge/control-chart-basics
- Detection rules explained: https://www.qimacros.com/control-chart/stability-analysis/
- I-charts vs X-bar charts: https://www.statology.org/i-chart-vs-xbar-chart/
